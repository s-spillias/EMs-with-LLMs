\setcounter{section}{0}
\renewcommand{\thesection}{S\arabic{section}}

\section{Curated Literature Collection}
\label{subsec:curated_literature}

The local document collection used in this case study was carefully curated to provide comprehensive coverage of marine ecosystem modeling approaches, with particular focus on COTS-coral dynamics and management interventions. The collection encompasses several key research areas:

\begin{itemize}
\item Ecosystem Modeling Frameworks: \cite{Plaganyi_2007} established foundational principles for ecosystem approaches to fisheries, while \cite{Plaganyi_Punt_Hillary_Morello_Thebaud_Hutton_Pillans_Thorson_Fulton_Smith_et_al_2014} introduced Models of Intermediate Complexity for Ecosystem assessments (MICE). \cite{Collie_Botsford_Hastings_Kaplan_Largier_Livingston_Plaganyi_Rose_Wells_Werner_2016} explored optimal model complexity levels.

\item COTS Management and Ecology: \cite{Pratchett_Caballes_Wilmes_Matthews_Mellin_Sweatman_Nadler_Brodie_Thompson_Hoey_et_al_2017} provided a comprehensive thirty-year review of COTS research. \cite{morello2014model} developed models for COTS outbreak management, while \cite{Rogers_Plaganyi_2022} analyzed corallivore culling impacts under bleaching scenarios.

\item Ecological Regime Shifts: \cite{Blamey_Plaganyi_Branch_2014} investigated predator-driven regime shifts in marine ecosystems. \cite{Plaganyi_Ellis_Blamey_Morello_Norman-Lopez_Robinson_Sporcic_Sweatman_2014} provided insights into ecological tipping points through ecosystem modeling.

\item Management Interventions: \cite{Condie_Anthony_Babcock_Baird_Beeden_Fletcher_Gorton_Harrison_Hobday_Plaganyi_et_al_2021} examined large-scale interventions on the Great Barrier Reef. \cite{Punt_MacCall_Essington_Francis_Hurtado-Ferro_Johnson_Kaplan_Koehn_Levin_Sydeman_2016} explored harvest control implications using MICE models.

\item Model Application Guidelines: \cite{Essington_Plaganyi_2014} provided critical guidelines for adapting ecosystem models to new applications. \cite{Gamble_Link_2009} demonstrated multispecies production model applications for analyzing ecological and fishing effects.

\item Integrated Systems: \cite{Hadley_Wild-Allen_Johnson_Macleod_2015} and \cite{Oca_Cremades_Jimenez_Pintado_Masalo_2019} explored integrated multi-trophic aquaculture modeling, providing insights into coupled biological systems. \cite{Spillias_Cottrell_2024} analyzed trade-offs in seaweed farming between food production, livelihoods, marine biodiversity, and carbon sequestration benefits.
\end{itemize}

These papers were selected based on their direct relevance to COTS population dynamics, coral reef ecology, and ecosystem modeling approaches. The collection provided both specific parameter values and broader ecological context for model development.

\section{RAG Architecture Implementation}
\label{subsec:rag_architecture}

The Retrieval-Augmented Generation (RAG) system facilitates parameter search and extraction from scientific literature. The system employs two primary search strategies: a local search of user-curated documents and a comprehensive web search. For local search, the system uses ChromaDB as a persistent vector store to maintain an indexed collection of scientific papers and technical documents specifically curated by research teams for their ecological systems. These documents are processed into semantic chunks of approximately 512 tokens with small overlaps to preserve context while enabling precise retrieval of relevant information.

The parameter search process begins with the generation of enhanced semantic descriptions for each parameter. These descriptions are crafted to improve search relevance by capturing the ecological and mathematical context in which the parameters are used. The system first searches the user-curated local documents using embeddings generated through Azure OpenAI's embedding service. When necessary, it extends to web-based sources through two channels: querying the Semantic Scholar database for highly-cited papers in biology, mathematics, and environmental science, and conducting broader literature searches through the Serper API to capture additional relevant sources.

The search results from both local and web sources are processed through an LLM to extract numerical values. The system applies consistent validation across both search pathways, identifying minimum and maximum bounds, ensuring unit consistency, and validating source reliability. When direct parameter values are not found in either the local collection or web sources, the system defaults to the initial estimates from the coding LLM. All extracted information, including parameter values, valid ranges, and complete citation details, is stored in a structured JSON database for reproducibility and future reference.

The RAG system implements automatic retry mechanisms when initial searches fail to yield usable results. Each retry attempt follows a structured progression: first accessing the curated local collection through ChromaDB queries, then expanding to Semantic Scholar for peer-reviewed literature, and finally utilizing Serper API for broader scientific content. This progressive broadening of scope, while maintaining focus on ecologically relevant sources, ensures robust parameter estimation even in cases where direct measurements are sparse in the literature.

\section{AI Prompts Used in Model Development}
\label{sec:ai_prompts}

The development of the model relied on several carefully crafted prompts to guide the artificial intelligence system. These prompts were designed to ensure numerical stability, proper likelihood calculation, and clear model structure. The following sections detail the exact prompts used at each stage of model development.

\subsection{Initial Model Creation}
\label{subsec:initial_model_prompt}

The initial model creation utilized a comprehensive prompt that emphasized three key aspects of model development. The prompt used for model initialization was:

\begin{lstlisting}
Please create a Template Model Builder model for the following topic:[PROJECT_TOPIC]. Start by writing intention.txt, in which you provide a concise summary of the ecological functioning of the model. In model.cpp, write your TMB model with the following important considerations:

1. NUMERICAL STABILITY:
- Always use small constants (e.g., Type(1e-8)) to prevent division by zero
- Use smooth transitions instead of hard cutoffs in equations
- Bound parameters within biologically meaningful ranges using smooth penalties rather than hard constraints

2. LIKELIHOOD CALCULATION:
- Always include observations in the likelihood calculation, don't skip any based on conditions
- Use fixed minimum standard deviations to prevent numerical issues when data values are small
- Consider log-transforming data if it spans multiple orders of magnitude
- Use appropriate error distributions (e.g., lognormal for strictly positive data)

3. MODEL STRUCTURE:
- Include comments after each line explaining the parameters (including their units and how to determine their values)
- Provide a numbered list of descriptions for the equations
- Ensure all important variables are included in the reporting section
- Use `_pred' suffix for model predictions corresponding to `_dat' observations
\end{lstlisting}

\subsection{Parameter Enhancement}
\label{subsec:parameter_enhancement_prompt}

To enhance parameter descriptions for improved semantic search capabilities, the following prompt was employed:

\begin{lstlisting}
Given a mathematical model about [PROJECT_TOPIC], enhance the semantic descriptions of these parameters to be more detailed and searchable. The model code shows these parameters are used in the following way:

[MODEL_CONTENT]

For each parameter below, create an enhanced semantic search, no longer than 10 words, that can be used for RAG search or semantic scholar search.
\end{lstlisting}

\subsection{Model Improvement}
\label{subsec:model_improvement_prompt}

For iterative model improvements, the system utilized this prompt:

\begin{lstlisting}
Improve the fit of the following ecological model by modifying the equations in this TMB script. Only make ONE discrete change most likely to improve the fit. Do not add stochasticity, but you may add other ecological relevant factors that may not be present here already.

You may add additional parameters if necessary, and if so, add them to parameters.json. Please concisely describe your ecological improvement in intention.txt and then provide the improved model.cpp and parameters.json content.

\end{lstlisting}

\subsection{Error Handling Prompts}
\label{subsec:error_handling_prompt}

For compilation errors, the system used this prompt:

\begin{lstlisting}
model.cpp failed to compile. Here's the error information:

[ERROR_INFO]

Do not suggest how to compile the script
\end{lstlisting}

For data leakage issues, the system employed this detailed prompt:

\begin{lstlisting}
Data leakage detected in model equations. The following response variables cannot be used to predict themselves:

To fix this:
1. Response variables ([RESPONSE_VARS]) must be predicted using only:
   - External forcing variables ([FORCING_VARS])
   - Other response variables' predictions (_pred variables)
   - Parameters and constants
2. Each response variable must have a corresponding prediction equation
3. Use ecological relationships to determine how variables affect each other

For example, instead of:
  slow_pred(i) = slow * growth_rate;
Use:
  slow_pred(i) = slow_pred(i-1) * growth_rate * (1 - impact_rate * cots_pred(i-1));

Please revise the model equations to avoid using response variables to predict themselves.
\end{lstlisting}

For numerical instabilities, the system used an adaptive prompt that became progressively more focused on simplification after multiple attempts:

\begin{lstlisting}
The model compiled but numerical instabilities occurred. Here's the error information:

[ERROR_INFO]

[After 2+ attempts: Consider making a much simpler model that we can iteratively improve later.]
Do not suggest how to compile the script
\end{lstlisting}

\subsection{NPZ Case Study - Recovering Equations}
\label{subsec:npz_evaluation_prompt}

The model implementation can be compared to the original NPZ equations from \cite{edwards1999zooplankton}:

\begin{align*}
    \frac{dN}{dt} &= \underbrace{-\frac{V_m N P}{k_s + N}}_{\text{nutrient uptake}}
                   + \underbrace{\gamma(1-\alpha)\frac{g P^2 Z}{k_g + P^2} + \mu_P P + \mu_Z Z^2}_{\text{recycling}}
                   + \underbrace{S(N_0 - N)}_{\text{mixing}} \\[6pt]
    \frac{dP}{dt} &= \underbrace{\frac{V_m N P}{k_s + N}}_{\text{growth}}
                   - \underbrace{\frac{g P^2 Z}{k_g + P^2}}_{\text{grazing loss}}
                   - \underbrace{\mu_P P}_{\text{mortality}}
                   - \underbrace{S P}_{\text{mixing}} \\[6pt]
    \frac{dZ}{dt} &= \underbrace{\alpha\frac{g P^2 Z}{k_g + P^2}}_{\text{growth (assimilation)}}
                   - \underbrace{\mu_Z Z^2}_{\text{mortality}}
                   - \underbrace{S Z}_{\text{mixing}}
    \end{align*}

Our generated model captures several key ecological processes from the original system:
\begin{enumerate}
\item Nutrient uptake by phytoplankton following Michaelis-Menten kinetics
\item Quadratic zooplankton mortality
\item Nutrient recycling through zooplankton excretion
\item Environmental mixing effects
\end{enumerate}

For evaluating the ecological characteristics of generated models against the NPZ reference model, the system employed a 4-level ordinal scoring system that compares each model component to both the ground truth equations and recognized alternate formulations from the ecological literature. The evaluation system assessed nine ecological characteristics organized by equation: nutrient uptake, recycling, and mixing (dN/dt); phytoplankton growth, grazing loss, mortality, and mixing (dP/dt); and zooplankton growth and mortality (dZ/dt).

The scoring rubric used for all evaluations was:

\begin{lstlisting}
Scoring rubric per characteristic (choose exactly one category):
- 3 = TRUTH_MATCH
    The mathematical structure is equivalent to the TRUTH model (modulo variable names,
    syntax, factor grouping, and coefficient naming). Quote the exact snippet that matches.
- 2 = ALTERNATE
    The implementation matches one of the alternates enumerated in the literature catalog,
    even if not identical to TRUTH. Name the family (e.g., "Michaelis-Menten uptake",
    "Ivlev grazing with threshold", "linear mortality", "Droop quota").
- 1 = SIMILAR_NOT_LISTED
    The implementation plays the same ecological role and is mathematically similar
    (e.g., another saturating curve or plausible closure) but is not represented in TRUTH
    or alternates list.
- 0 = NOT_PRESENT_OR_INCORRECT
    The ecological component is missing or cannot be identified.
\end{lstlisting}

The alternate formulations catalog was based on \cite{franks2002npz} and included:

\begin{itemize}
    \item Phytoplankton light response: linear, saturating (Michaelis-Menten, exponential, tanh), and photo-inhibiting forms
    \item Nutrient uptake: Michaelis-Menten, Liebig minimum limitation, Droop quota models
    \item Zooplankton grazing: linear, saturating with threshold, Holling/Ivlev type, acclimating forms
    \item Mortality terms: linear and quadratic (density-dependent) for both phytoplankton and zooplankton
\end{itemize}

Each characteristic was assigned a weight based on its contribution to its parent equation: the three nutrient equation components each had weight 0.333, the four phytoplankton components each had weight 0.25, and the two zooplankton components each had weight 0.5. The aggregate ecological score was calculated as the weighted sum of individual scores, then normalized to a 0-1 scale by dividing by the maximum possible score.

\subsubsection{Validation of Scoring System}

To validate the ecological characteristics scoring system, we tested it on the ground truth NPZ model itself (evaluating the model against its own equations). This test confirmed that the scoring system could correctly identify and score all nine ecological characteristics when they were present in their canonical forms.

The validation results demonstrated perfect performance:

\begin{itemize}
    \item All nine characteristics received scores of 3 (TRUTH\_MATCH)
    \item Raw total score: 8.997 (out of maximum 9.0, with small rounding due to floating point arithmetic)
    \item Normalized total score: 1.0000 (perfect score on 0-1 scale)
    \item Zero extra components identified (correctly recognized model contained only canonical NPZ processes)
\end{itemize}

The LLM evaluator correctly identified each ecological mechanism in the ground truth model, providing detailed explanations such as ``algebraically identical to the TRUTH NPZ model'' and specifically noting the presence of ``Michaelis-Menten style nutrient limitation multiplied by a light/self-shading term for phytoplankton growth'' and ``a saturating P\textsuperscript{2}/(µ\textsuperscript{2}+P\textsuperscript{2}) (Hill/Type-III-like) grazing formulation.'' This validation confirmed that the scoring system could reliably distinguish between different levels of ecological fidelity, from exact matches to the ground truth through recognized alternates to novel formulations, providing a robust framework for assessing LEMMA-generated models.

\section{NPZ Validation}
\label{sec:npz_validation}

% \begin{figure}[H]
% \centering
% \includegraphics[width=\textwidth]{../Figures/ecological_characteristics_vs_objective}
% \caption{Relationship between ecological accuracy scores and model performance for each NPZ model characteristic. Each panel shows how well models recovered a specific ecological mechanism (score from 0-1) versus their predictive accuracy (objective value). Lower objective values indicate better model fit. Two-sided Pearson's product-moment correlation coefficients (r) and their associated p-values are shown for each characteristic.}
% \label{fig:ecological_characteristics}
% \end{figure}

\input{npz_analysis.tex}

\section{CoTS Model Convergence}
\label{sec:convergence}
% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.8\textwidth]{../Figures/founder_to_terminal_evolution.png}
%     \caption{Evolution of model performance across generations. The plot shows the progression of objective values from an initial successful individual to the final individual in the lineage (either due to process termination or culling). Single dots represent individuals which were not improved upon in any subsequent iterations.}
%     \label{fig:evolution}
%     \end{figure}

    
\subsection{Model Evolution and Convergence}
The evolutionary process exhibited consistent refinement across generations, with measurable improvements in model performance. On average, populations reached their best-performing individual within 6.9 generations, and the mean improvement frequency across all populations was 38.0\%. Figure \ref{fig:status_distribution} shows the distribution of successful, culled, and broken models across generations. Notably, two populations achieved convergence below the target threshold, representing 9.5\% of all populations.
Performance varied significantly across populations. The fastest-converging population reached an optimal objective value of 0.0035 in just 3 generations, while others required up to 13 generations. This population also demonstrated a high improvement rate of -0.655 and a consistent improvement frequency of 50\%. In contrast, several populations showed minimal or no improvement, with some failing to converge within the allotted iterations.
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{../Figures/success_frequency}
\caption{Evolution of model performance during the genetic algorithm optimization process. Each generation represents an iteration of model development, where models are evaluated and classified into three categories: the best performers according to the NMSE objective value (kept, green), those that are numerically stable but outcompeted (culled, blue), and those that failed due to numerical instability, data leakage, or syntax errors (broken, orange). The vertical axis shows the count of new models in each category per generation, while rows represent independent replicates using different LLM configurations. Gemini-2.5-Pro was included in the analysis but did not produce successful runs for some populations.}
\label{fig:status_distribution}
\end{figure}

\subsection{Numerical Stability and Optimization}
Numerical stability varied across LLM configurations, with runtime and generation time metrics reflecting differences in optimization efficiency. The GPT-5 configuration showed moderate efficiency, with an average generation time of 12.0 minutes (SD = 13.0). The Claude Sonnet 4.5 configuration had longer generation times, averaging 71.2 minutes (SD = 155.2), though this includes variability from a small number of outlier populations. In contrast, the Gemini-2.5-Pro configuration demonstrated the fastest generation cycles, averaging 4.1 minutes per generation (SD = 0.54), though it exhibited lower convergence rates and higher instability in some cases.
Figure \ref{fig:iterations_by_llm} illustrates the distribution of iteration counts required for successful model convergence across LLMs. Most models converged within 4 to 7 iterations, with some outliers requiring up to 11 iterations.
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{../Figures/iterations_by_llm}
\caption{Distribution of iteration counts for successful model instances by LLM configuration. The boxplot excludes cases that reached maximum iterations or remained numerically unstable.}
\label{fig:iterations_by_llm}
\end{figure}

\input{model_analysis.tex}

% \input{best_models_read.tex}
\input{best_models/oos_best_read.tex}

