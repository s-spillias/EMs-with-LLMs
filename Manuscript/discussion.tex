Our complementary validation studies demonstrate the viability of AI-driven automation in ecological model development and calibration. The NPZ validation revealed AIME's ability to recover known ecological relationships from synthetic data, with the best models achieving high ecological accuracy scores (up to 7.75 out of 8) while maintaining strong predictive performance (objective values as low as 0.112). While AIME did not perfectly reconstruct the original equations after 50 generations, it successfully identified key mechanisms like Michaelis-Menten kinetics and predator-prey interactions. The negative correlation between ecological accuracy and objective values suggests that improvements in model fit were achieved through discovery of correct ecological relationships rather than overfitting. This ability to balance model fit with ecological realism represents a significant advance in automated ecological modelling.

The CoTS case study further demonstrated AIME's practical utility, with AIME successfully generating models that approached the predictive performance of human expert models, albeit with less consistency across all variables. While the AI-derived models captured key ecological dynamics, they did so using structurally simpler formulations, and their performance varied depending on the specific ecosystem component being modeled.

Notably, the AI-generated models achieved predictive performance that was broadly similar to that of the human expert model, despite substantial structural differences. These results suggest that, under certain conditions, AI-driven approaches may approximate expert-level outcomes, though further validation and refinement are needed to ensure robustness and ecological fidelity (see Supplementary Materials for detailed comparison). While the human model implemented an age-structured COTS population with explicit age classes and a Beverton-Holt stock-recruitment relationship, the AI models generally employed simpler, unstructured population approaches. Similarly, the human model featured an explicit prey-switching function for COTS predation preference between coral types, whereas AI models used various functional responses ranging from coral-dependent reproduction to logistic growth with food limitation. These structural differences highlight an important trade-off: the human model exhibited greater mechanistic detail reflecting domain expertise and input from domain experts, while AI models achieved similar performance with more parsimonious formulations. This is consistent with the coexistence of multiple numerically valid representations of the same
ecological system where each offers different insights into the underlying mechanisms \citep{patterson2001estimating}, with each offering different insights into underlying mechanisms. This method provides a valuable opportunity for researchers to explore diverse ecological mechanisms while maintaining comparable predictive performance.

Importantly, this flexibility also opens the door to hybrid approaches that combine the strengths of both expert-driven and AI-generated models. By explicitly prompting the AI to include particular ecological processes, such as age structure, prey-switching behavior, or nutrient mixing, researchers can guide model structure to reflect known system dynamics or stakeholder priorities. This capability enhances the utility of AI-generated models for hypothesis testing, scenario exploration, and applied decision-making, particularly in contexts where certain mechanisms are known to be ecologically or socially important. This method provides a valuable opportunity for researchers to explore diverse ecological mechanisms while maintaining comparable predictive performance. The ability to generate multiple, distinct models for a given system opens up new avenues for future research, allowing for the exploration of different ecological hypotheses and the potential for ensemble modelling approaches.


\subsection{Contrasting Approaches to AI in Ecological Modelling}
Recent advances in AI have demonstrated remarkable capabilities in ecological time-series prediction. Studies using transformer architectures and diffusion models, including multimodal approaches like LITE \citep{li2024lite}, have shown high accuracy in direct forecasting of environmental variables \citep{morales2024developing,gandhi2024generative}. While these methods effectively handle challenges like missing data and distribution shifts, they treat the system as a black box, learning patterns directly from time-series data without explicitly modelling underlying mechanisms. While our study did not directly compare our approach with black-box methods, our NPZ validation study suggests a key advantage of our approach: the ability to provide insights into fundamental ecological processes like nutrient cycling or predator-prey dynamics through explicit model discovery. This interpretability is a theoretical advantage over black-box approaches, though comparative studies would be needed to fully evaluate the relative strengths of each approach in specific ecological contexts.

Our evolutionary approach fundamentally differs by using AI to generate actual ecological models rather than make direct predictions. Instead of training neural networks to forecast future values, AIME evolves interpretable models with meaningful parameters that capture real biological and physical processes. This distinction is crucial for several reasons. First, our generated models provide scientific insight into system behavior, revealing mechanisms and relationships that direct prediction approaches typically cannot without careful oversight \citep{adams2017model}. Second, the models maintain biological plausibility through explicit parameter constraints and mechanistic formulations, ensuring their utility for management applications. Third, because they capture fundamental processes rather than just patterns, these models can potentially be transferred to new scenarios and used to explore management interventions.
The relationship between our approach and direct prediction methods is nuanced. Recent time-series prediction approaches using transformer architectures have achieved impressive accuracy, with mean squared errors as low as 0.001-0.04 for normalized predictions \citep{morales2024developing} and root mean squared errors reduced by up to 52\% compared to traditional methods \citep{gandhi2024generative}. While our evolved models may not always match these pure prediction accuracies, they offer advantages in interpretability, scientific insight and potential for strategic and tactical applications.

Importantly, these approaches need not be viewed as mutually exclusive. Comparing mechanistic models with black-box predictions can be particularly insightful, especially when the two approaches diverge. For instance, under novel conditions like future climate scenarios, differences in predictions could highlight processes that are not well-captured by mechanistic models or reveal patterns that black-box approaches detect but cannot explain. When predictive approaches outperform mechanistic models, this divergence can guide researchers toward missing processes or relationships that should be incorporated into mechanistic understanding. Our framework demonstrates that it's possible to achieve both reasonable predictive accuracy and meaningful ecological interpretability, with each approach offering complementary strengths.

This focus on model generation rather than direct prediction aligns with the needs of ecosystem-based management, where mechanistic understanding is as important as predictive accuracy. The interpretability of AI-evolved models enables users to assess the credibility of predictions and understand the mechanisms driving system behavior thereby allowing for informed management interventions, advantages not readily available with black-box prediction approaches. Work examining automated scientific discovery emphasizes the importance of maintaining human oversight while leveraging AI's computational capabilities \citep{kramer2023automated,Spillias2024}. Our approach directly addresses this need by producing interpretable models that facilitate meaningful human oversight while leveraging AI's capabilities for systematic exploration of model space. Crucially, this process is not solely computational: models are refined through expert collaboration, which synthesizes domain knowledge and builds confidence and legitimacy in the resulting models. This step is essential for filtering out plausible but ultimately incorrect mechanisms that may arise from AI-driven parsimony. For example, some temperature-related functions affecting COTS in the AI-derived models lack empirical support and thus their inclusion would likely be removed during expert-led refinement. While such mechanisms may be ecologically plausible, their inclusion without validation risks misleading management decisions, especially under extreme conditions. Thus, expert review acts as an important filter, ensuring that models are not only interpretable, but also credible and useful for decision-making.

\subsection{Limitations and Future Directions}

Despite promising results, several limitations warrant consideration. The observed variation in convergence rates across populations suggests that initial conditions significantly influence model evolution trajectories. While the best performing population achieved rapid convergence within five generations, other populations required more than twice as many generations to approach similar performance levels. 

An important limitation in our current implementation is the treatment of all model parameters as estimable quantities in the optimization process, even when well-established values exist in the literature. While our RAG system successfully retrieves some literature-based values and ranges for parameters, these are only used as initial estimates and bounds rather than as fixed quantities. This approach may lead to unnecessary parameter estimation and potential deviation from biologically meaningful values. Future versions of the framework should distinguish between parameters that truly need estimation and those that could be fixed based on reliable literature values. This would not only reduce the parameter space for optimization but also better incorporate established ecological knowledge into the modelling process and make the process less resource-intensive when doing calculations.

There are numerous future avenues for validating, improving, and extending this framework. First, there are several hyper-parameters that likely control the success and speed of convergence of the framework (LLM-choice, LLM temperature setting, number of individuals per generation, prompt construction, etc.). Systematic testing across these choices may reveal optimal configurations for convergence. In particular, the comparative analysis of different AI configurations (as detailed in Section \ref{sec:cots_data} and Figure \ref{fig:status_distribution}) reveals trade-offs between model choice and rate of improvement. While the o3-mini and o4-mini configurations were consistently able to iteratively improve, the Sonnet models and GPT 4.1 model were often able to perform well in a single generation but then did not consistently improve. Future work could explore hybrid approaches that leverage the strengths of different AI configurations at various stages of model development, or that employ different LLMs consecutively over multiple generations. Further, ongoing testing of new LLMs as they are released may yield considerable gains in efficiency and cost-saving. Second, we have tested a relatively simple ecosystem model with three dependent variable time-series and two forcing variable time-series. Simple systems like these will be limited in real-world utility, and therefore testing on more complex systems with tens or hundreds of time-series will be needed. Incorporating spatial components may also be possible and will greatly improve the utility of this framework. Third, accessing relevant scientific information for the parameter RAG search is limited by the user's ability to either curate a local database of relevant materials, or access scientific papers online. Fourth, we have demonstrated that it is possible for this LLM-based system to generate multiple, distinct models for a given system. Choosing between similarly performing, but ecologically distinct models may be necessary for experts with ecological knowledge, or perhaps employing approaches that ensemble multiple plausible models may allow for the reduction in uncertainty \citep{baker2017ensemble,gaardmark2013biological,vollert2024unlocking}

\subsection{Implications for Ecosystem-Based Fisheries Management}

The successful application of AIME to COTS populations on the Great Barrier Reef demonstrates its potential for use in developing plausible models that can provie insights on pressing ecosystem problems relevant to ecosystem based management. While more development and experience is needed to ascertain AI-derived models directly into decision making contexts, there is certainly sufficient evidence that they can be used as a means of
hypothesis generation and for the development of plausible models. This radically speeds up model buildng, bringing the process more into line with timeframes pertinent to pressing tactical management questions. The framework's capacity to capture both short-term outbreak dynamics and longer-term ecosystem changes provides scientists supporting managers with valuable insights for intervention planning. The comparable performance between AI-generated models and human expert approaches suggests that automated modelling could complement traditional methods, accelerating the development and evaluation of management strategies.

Notably, the speed of implementation achieved through our framework significantly outpaces what a human modeller can manage working independently, with model generation and refinement occurring in hours rather than weeks or months. This enhanced efficiency creates capacity for more timely intervention in response to emerging ecological threats, such as in biosecurity emergencies, where management actions depend on rapid model development and deployment. AIME's ability to integrate multiple data sources, both locally and from web search, and account for both biological and environmental factors provides a robust foundation for developing early warning systems and evaluating potential management interventions.\

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../Figures/AIME_workflow.drawio.png}
    \caption{The AIME framework workflow integrating human expertise with AI-driven model development. The diagram illustrates how stakeholder engagement, time-series data, and prior ecological knowledge inform the AIME process, which generates candidate models that can be evaluated and refined by human experts, ultimately supporting ecosystem management decisions.}
    \label{fig:aime_workflow}
\end{figure}


To ensure safe and effective integration of AIME into ecosystem-based fisheries management, we recommend a set of best practices and propose that AIME would work best embedded within a human-driven workflow (Figure \ref{fig:aime_workflow}). 

\begin{enumerate}
    \item \textbf{Stakeholder Engagement}  
    Begin with stakeholder engagement to inform problem framing and define the ecological questions AIME will address. Early involvement ensures models are relevant to management needs and incorporate local knowledge.

    \item \textbf{Expert Review}  
    All AI-generated models should be reviewed by domain experts to validate ecological plausibility and ensure alignment with management objectives.

    \item \textbf{Complementary Use}  
    Use AIME as a complementary tool that supports - rather than replaces - traditional modelling workflows, especially for rapid prototyping or exploring alternative hypotheses.

    \item \textbf{Model Transparency}  
    Maintain transparency through clear documentation of equations, parameters, and assumptions to ensure traceability and reproducibility.

    \item \textbf{Parameter Assessment}  
    Critically assess parameter values sourced from literature. Fix well-established values where appropriate to reduce uncertainty.

    \item \textbf{Rigorous Validation}  
    Conduct thorough validation, including cross-validation and out-of-sample testing, before applying models to decision-making.

    \item \textbf{Training and Capacity Building}  
    Provide training to ensure managers and researchers can interpret and apply AI-generated models responsibly.
\end{enumerate}

In conclusion, AIME represents an advancement in ecological modelling that bridges the gap between computational efficiency and ecological insight. By dramatically accelerating model development while maintaining scientific rigour, this framework offers a powerful new tool for researchers and managers facing urgent ecological challenges. As environmental pressures intensify globally, the capacity to rapidly develop, test, and deploy ecologically sound models will become increasingly valuable for effective conservation and management of marine ecosystems.

