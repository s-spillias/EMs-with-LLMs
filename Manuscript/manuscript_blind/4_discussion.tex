Our complementary validation studies demonstrate the viability of AI-driven automation in ecological model development and calibration. The NPZ validation revealed LEMMA's ability to recover known ecological relationships from synthetic data, with the best-fitting individual achieving a normalized ecological score of 0.676, which is moderately good and reflects recovery of all mechanisms except phytoplankton mixing; the remaining components were either identical to the NPZ reference model or accepted alternatives from \cite{franks2002npz} (objective value = 0.0035), while the highest ecological score observed was 0.898 for a different individual with a higher objective error (objective value = 0.650) While LEMMA did not perfectly reconstruct the original equations after ten generations, it successfully identified key mechanisms like Michaelis-Menten kinetics and predator-prey interactions. The negative correlation between ecological accuracy and objective values suggests that improvements in model fit were achieved through discovery of correct ecological relationships rather than overfitting. This ability to balance model fit with ecological realism represents an important advance in ecological modelling.

The CoTS case study further demonstrated LEMMA's practical utility, with LEMMA successfully generating models that approached the predictive performance of human expert models, albeit with less consistency across all variables. While LEMMA' models captured key ecological dynamics, they did so using structurally simpler formulations, and their performance varied depending on the specific ecosystem component being modeled.

Notably, LEMMA-generated models achieved predictive performance that was broadly similar to that of the human expert model, despite substantial structural differences. These results suggest that, under certain conditions, AI-driven approaches may approximate expert-level outcomes, though further validation and refinement are needed to ensure robustness and ecological fidelity (see Supplementary Materials for detailed comparison). While the human model implemented an age-structured COTS population with explicit age classes and a Beverton-Holt stock-recruitment relationship, LEMMA models generally employed simpler, unstructured population approaches. Similarly, the human model featured an explicit prey-switching function for COTS predation preference between coral types, whereas AI models used various functional responses ranging from coral-dependent reproduction to logistic growth with food limitation. These structural differences highlight an important trade-off: the human model exhibited greater mechanistic detail reflecting domain expertise and input from domain experts, while AI models achieved similar performance with more parsimonious formulations. This is consistent with the coexistence of multiple numerically valid representations of the same ecological system where each offers different insights into the underlying mechanisms \citep{patterson2001estimating}. 

Importantly, our findings also address the “forecast trap” described by \citep{Boettiger2022}, wherein selecting models primarily on predictive skill can lock decision-makers into policies that are accurate in forecast space but suboptimal in utility space. In capacity-constrained settings, having even a single model is often a luxury, and assembling an ensemble is typically out of reach. We hope that LEMMA, or tools like it, will enable diverse sets of models to be built, compared, and ensembled with relative ease. By evolving interpretable mechanistic candidates, LEMMA broadens the model set and supports robust decision workflows, reducing the risk of converging on a well-calibrated yet policy-misaligned model.

This flexibility also opens the door to hybrid approaches that combine the strengths of both expert-driven and AI-generated models. By explicitly prompting LEMMA to include particular ecological processes, such as age structure, prey-switching behavior, or nutrient mixing, researchers can guide model structure to reflect known system dynamics or stakeholder priorities. This capability enhances the utility of AI-generated models for hypothesis testing, scenario exploration, and applied decision-making, particularly in contexts where certain mechanisms are known to be ecologically or socially important. 

An important consideration in automated model generation is the provenance of parameter values. In this study, we restricted parameter retrieval to curated local literature and Semantic Scholar searches to ensure reliance on peer-reviewed information, noting that LEMMA incorporates the ability to also perform general web sources should the user choose. While restricting the source of parameter values improves transparency and scientific rigor, it also means that when literature values were unavailable, the system defaulted to LLM-derived initial estimates, which - though often plausible - lack explicit citation. Future enhancements such as user-defined whitelists and confidence scoring to further strengthen parameter provenance may help to address these limitations.

Unlike traditional machine-learning approaches which use regularisation and early-stopping to avoid overfitting. LEMMA employs two nested optimisation processes, both of may need mechanisms to address overfitting. For parameter estimation within TMB, literature-informed bounds act as weak regularisation, but no additional penalties are applied. For structural evolution, we limit changes to one modification per generation and cap the number of generations. In the NPZ case study, improvements in fit were negatively correlated with ecological accuracy scores, suggesting that gains were achieved through mechanistically sound changes rather than overfitting. Nonetheless, explicit complexity penalties or information-theoretic criteria (e.g., AIC/BIC) could further reduce overfitting risk in future iterations.

\subsection{Contrasting Approaches to AI in Ecological Modelling}
Recent advances in AI have demonstrated remarkable capabilities in ecological time-series prediction. Studies using transformer architectures and diffusion models, including multimodal approaches like LITE \citep{li2024lite}, have shown high accuracy in direct forecasting of environmental variables \citep{morales2024developing,gandhi2024generative}. While these methods effectively handle challenges like missing data and distribution shifts, they treat the system as a black box, learning patterns directly from time-series data without explicitly modelling underlying mechanisms. While our study did not directly compare our approach with black-box methods, our NPZ validation study suggests a key advantage of our approach: the ability to provide insights into fundamental ecological processes like nutrient cycling or predator-prey dynamics through explicit model discovery. This interpretability is a theoretical advantage over black-box approaches, though comparative studies would be needed to fully evaluate the relative strengths of each approach in specific ecological contexts.

Our evolutionary approach fundamentally differs by using AI to generate actual ecological models rather than make direct predictions. Instead of training neural networks to forecast future values, LEMMA evolves interpretable models with meaningful parameters that capture real biological and physical processes. This distinction is crucial for several reasons. First, our generated models provide scientific insight into system behavior, revealing mechanisms and relationships that direct prediction approaches typically cannot without careful oversight \citep{adams2017model}. Second, the models maintain biological plausibility through explicit parameter constraints and mechanistic formulations, ensuring their utility for management applications. Third, because they capture fundamental processes rather than just patterns, these models can potentially be transferred to new scenarios and used to explore management interventions.
The relationship between our approach and direct prediction methods is nuanced. Recent time-series prediction approaches using transformer architectures have achieved impressive accuracy, with mean squared errors as low as 0.001-0.04 for normalized predictions \citep{morales2024developing} and root mean squared errors reduced by up to 52\% compared to traditional methods \citep{gandhi2024generative}. While our evolved models may not always match these pure prediction accuracies, they offer advantages in interpretability, scientific insight and potential for strategic and tactical applications.

Importantly, these approaches need not be viewed as mutually exclusive. Comparing mechanistic models with black-box predictions can be particularly insightful, especially when the two approaches diverge. For instance, under novel conditions like future climate scenarios, differences in predictions could highlight processes that are not well-captured by mechanistic models or reveal patterns that black-box approaches detect but cannot explain. When predictive approaches outperform mechanistic models, this divergence can guide researchers toward missing processes or relationships that should be incorporated into mechanistic understanding. Our framework demonstrates that it's possible to achieve both reasonable predictive accuracy and meaningful ecological interpretability, with each approach offering complementary strengths.

This focus on model generation rather than direct prediction aligns with the needs of ecosystem-based management, where mechanistic understanding is as important as predictive accuracy. The interpretability of AI-evolved models enables users to assess the credibility of predictions and understand the mechanisms driving system behavior thereby allowing for informed management interventions, advantages not readily available with black-box prediction approaches. Work examining automated scientific discovery emphasizes the importance of maintaining human oversight while leveraging AI's computational capabilities \citep{kramer2023automated,Spillias2024}. Our approach directly addresses this need by producing interpretable models that facilitate meaningful human oversight while leveraging AI's capabilities for systematic exploration of model space. Crucially, this process is not solely computational: models are refined through expert collaboration, which synthesizes domain knowledge and builds confidence and legitimacy in the resulting models. This step is essential for filtering out plausible but ultimately incorrect mechanisms that may arise from AI-driven parsimony. For example, some temperature-related functions affecting COTS in LEMMA-derived models lack empirical support and thus their inclusion would likely be removed during expert-led refinement. While such mechanisms may be ecologically plausible, their inclusion without validation risks misleading management decisions, especially under extreme conditions. Thus, expert review acts as an important filter, ensuring that models are not only interpretable, but also credible and useful for decision-making.

\subsection{Limitations and Future Directions}

Despite promising results, several limitations warrant consideration. The observed variation in convergence rates across populations suggests that initial conditions significantly influence model evolution trajectories. While the best performing population achieved rapid convergence within five generations, other populations required more than twice as many generations to approach similar performance levels. In our current pipeline, convergence is also affected by the phased optimisation schedule and box-constraint handling: parameters are estimated in priority-ordered phases with starts clamped into literature- or LLM-derived bounds and pathological intervals normalised. Although these safeguards improve numerical stability, they can also interact with initial conditions in nontrivial ways (e.g., temporarily parking parameters on bound faces early in the schedule and delaying subsequent improvements).

An important limitation in our current implementation is the treatment of all model parameters as estimable quantities in the optimization process, even when well-established values exist in the literature. While our RAG system successfully retrieves literature-based values and ranges, these are used as initial estimates and bounds rather than fixed quantities. This design choice reflects the reality that literature values may not always be appropriate for the specific ecological context being modeled. Estimating parameters within literature-derived bounds allows the model to adapt to system-specific deviations, offering greater flexibility and ecological realism. Future versions of the framework could distinguish between parameters that truly require estimation and those that could be fixed, reducing the parameter space and improving computational efficiency. This would not only reduce the parameter space for optimization but also better incorporate established ecological knowledge into the modelling process and make the process less resource-intensive when doing calculations.

One limitation identified in this study is the low level of citation integration. Only about 3\% of parameters are linked to explicit sources. It is reasonable to expect that not all parameters would have readily available citations because many are scaling constants or other mathematical utility parameters that typically do not appear in the literature. This gap is also unsurprising given that the parameter search in this study relied only on abstracts from Semantic Scholar, while full-text scientific articles are often locked behind paywalls.
This situation highlights the importance of human oversight. Experts can build on LEMMA's outputs by supplementing parameterization with their own efforts, ensuring that critical biological parameters are grounded in empirical evidence while computational parameters remain transparent and well documented.
LLMs have been demonstrated to perform well at extracting ecological data from curated databases \citep{gougherty2024testing,keck2025extracting}, therefore we expect that an important first step before deploying LEMMA would be to provide it with as much high-quality information as possible. Future iterations of LEMMA could address these limitations by incorporating more flexible agentic frameworks that can dynamically access curated databases and apply advanced reasoning to identify high-quality sources during web searches. Such improvements would enable the system to prioritize peer-reviewed literature, apply confidence scoring, and cross-validate retrieved values against multiple sources. These enhancements would strengthen parameter provenance and reduce reliance on uncited estimates generated by language models.

It is important to note that our prompt provided only high-level guidance on ecological realism, numerical stability, and reporting requirements, without specifying how parameter estimation should be implemented in TMB. Despite this minimal guidance, the LLM consistently generated models that adopt a forward-simulation approach: initializing at the first observation, simulating trajectories through time, and minimizing a trajectory-wide error metric. This convergence on a single strategy suggests that, under generic ecological modelling prompts, LLMs may default to conceptually straightforward but computationally fragile approaches. Future work could explore this outcome by explicitly prompting for alternative estimation paradigms, such as state-space formulations \citep{auger2021guide}, gradient matching \citep{ellner2002fitting}, or one-step-ahead prediction objectives \citep{munch2023recent}, thereby enabling systematic comparison of inference strategies within the same automated workflow.

There are numerous future avenues for validating, improving, and extending this framework. First, there are several hyper-parameters that likely control the success and speed of convergence of the framework (LLM-choice, LLM temperature setting, number of individuals per generation, prompt construction, etc.). Systematic testing across these choices may reveal optimal configurations for convergence. In particular, the comparative analysis of different AI configurations (as detailed in section S5.1 %\ref{sec:cots_data} 
and Supplemental Figure 1%\ref{fig:status_distribution}
) reveals trade-offs between model choice and rate of improvement. While GPT-5 demonstrated the most stable improvement and achieved the best overall performance, Sonnet-4.5 and Gemini-Pro-2.5 often produced strong initial models but did not consistently improve across generations. Future work could explore hybrid approaches that leverage the strengths of different LLMs at various stages of model development, or employ different models consecutively over multiple generations. Further, ongoing testing of new LLMs as they are released may yield considerable gains in efficiency and cost-saving. Second, we have tested a relatively simple ecosystem model with three dependent variable time-series and two forcing variable time-series. Simple systems like these will be limited in real-world utility, and therefore testing on more complex systems with tens or hundreds of time-series will be needed. Incorporating spatial components may also be possible and will greatly improve the utility of this framework. Third, accessing relevant scientific information for the parameter RAG search is limited by the user's ability to either curate a local database of relevant materials, or access scientific papers online. Fourth, we have demonstrated that it is possible for this LLM-based system to generate multiple, distinct models for a given system. Choosing between similarly performing, but ecologically distinct models may be necessary for experts with ecological knowledge, or perhaps employing approaches that ensemble multiple plausible models may allow for the reduction in uncertainty \citep{baker2017ensemble,gaardmark2013biological,vollert2024unlocking}. Finally, our evaluation approach relies mainly on error-based metrics, which may not fully reflect ecological plausibility. Recent work on LLM-based evaluation policy extraction \citep{cheng2025llm} offers a promising direction for incorporating expert-informed, interpretable criteria into automated workflows. Future versions of our framework could integrate such methods to improve ecological relevance in model selection.

\subsection{Implications for Ecosystem-Based Fisheries Management}

The successful application of LEMMA to COTS populations on the Great Barrier Reef demonstrates its potential for use in developing plausible models that can provie insights on pressing ecosystem problems relevant to ecosystem based management. While more development and experience is needed to ascertain AI-derived models directly into decision making contexts, there is certainly sufficient evidence that they can be used as a means of
hypothesis generation and for the development of plausible models. This may help to accelerate the model-building process, bringing the process more into line with timeframes pertinent to pressing tactical management questions. The framework's capacity to capture both short-term outbreak dynamics and longer-term ecosystem changes provides scientists supporting managers with valuable insights for intervention planning. The comparable performance between AI-generated models and human expert approaches suggests that automated modelling could complement traditional methods, accelerating the development and evaluation of management strategies.

While the current implementation of LEMMA demonstrates faster turnaround than typical manual workflows, reducing model development from weeks or months to hours, these gains reflect relatively simple case studies. As LEMMA matures and is tested in more complex systems, this enhanced efficiency may create capacity for more timely intervention in response to emerging ecological threats, such as in biosecurity emergencies, where management actions depend on rapid model development and deployment. LEMMA's ability to integrate multiple data sources, both locally and from web search, and account for both biological and environmental factors provides a robust foundation for developing early warning systems and evaluating potential management interventions.\

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{../Figures/AIME_workflow.drawio.png}
    \caption{The LEMMA framework workflow integrating human expertise with AI-driven model development. The diagram illustrates how stakeholder engagement, time-series data, and prior ecological knowledge inform the LEMMA process, which generates candidate models that can be evaluated and refined by human experts, ultimately supporting ecosystem management decisions.}
    \label{fig:aime_workflow}
\end{figure}


To ensure safe and effective integration of LEMMA into ecosystem-based fisheries management, we recommend a set of best practices and propose that LEMMA would work best embedded within a human-driven workflow (Figure \ref{fig:aime_workflow}). 

\begin{enumerate}
    \item \textbf{Stakeholder Engagement}  
    Begin with stakeholder engagement to inform problem framing and define the ecological questions LEMMA will address. Early involvement ensures models are relevant to management needs and incorporate local knowledge.

    \item \textbf{Expert Review}  
    All AI-generated models should be reviewed by domain experts to validate ecological plausibility and ensure alignment with management objectives.

    \item \textbf{Complementary Use}  
    Use LEMMA as a complementary tool that supports - rather than replaces - traditional modelling workflows, especially for rapid prototyping or exploring alternative hypotheses.

    \item \textbf{Model Transparency}  
    Maintain transparency through clear documentation of equations, parameters, and assumptions to ensure traceability and reproducibility.

    \item \textbf{Parameter Assessment}  
    Critically assess parameter values sourced from literature. Fix well-established values where appropriate to reduce uncertainty.

    \item \textbf{Rigorous Validation}  
    Conduct thorough validation, including cross-validation and out-of-sample testing, before applying models to decision-making.

    \item \textbf{Training and Capacity Building}  
    Provide training to ensure managers and researchers can interpret and apply AI-generated models responsibly.
\end{enumerate}

In conclusion, LEMMA represents an advancement in ecological modelling that bridges the gap between computational efficiency and ecological insight. By dramatically accelerating model development while maintaining scientific rigour, this framework offers a powerful new tool for researchers and managers facing urgent ecological challenges. As environmental pressures intensify globally, the capacity to rapidly develop, test, and deploy ecologically sound models will become increasingly valuable for effective conservation and management of marine ecosystems.

