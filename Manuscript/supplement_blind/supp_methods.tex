\section{Curated Literature Collection}
\label{subsec:curated_literature}

The local document collection used in this case study was carefully curated to provide comprehensive coverage of marine ecosystem modeling approaches, with particular focus on COTS-coral dynamics and management interventions. The collection encompasses several key research areas:

\begin{itemize}
\item Ecosystem Modeling Frameworks: \cite{Plaganyi_2007} established foundational principles for ecosystem approaches to fisheries, while \cite{Plaganyi_Punt_Hillary_Morello_Thebaud_Hutton_Pillans_Thorson_Fulton_Smith_et_al_2014} introduced Models of Intermediate Complexity for Ecosystem assessments (MICE). \cite{Collie_Botsford_Hastings_Kaplan_Largier_Livingston_Plaganyi_Rose_Wells_Werner_2016} explored optimal model complexity levels.

\item COTS Management and Ecology: \cite{Pratchett_Caballes_Wilmes_Matthews_Mellin_Sweatman_Nadler_Brodie_Thompson_Hoey_et_al_2017} provided a comprehensive thirty-year review of COTS research. \cite{morello2014model} developed models for COTS outbreak management, while \cite{Rogers_Plaganyi_2022} analyzed corallivore culling impacts under bleaching scenarios.

\item Ecological Regime Shifts: \cite{Blamey_Plaganyi_Branch_2014} investigated predator-driven regime shifts in marine ecosystems. \cite{Plaganyi_Ellis_Blamey_Morello_Norman-Lopez_Robinson_Sporcic_Sweatman_2014} provided insights into ecological tipping points through ecosystem modeling.

\item Management Interventions: \cite{Condie_Anthony_Babcock_Baird_Beeden_Fletcher_Gorton_Harrison_Hobday_Plaganyi_et_al_2021} examined large-scale interventions on the Great Barrier Reef. \cite{Punt_MacCall_Essington_Francis_Hurtado-Ferro_Johnson_Kaplan_Koehn_Levin_Sydeman_2016} explored harvest control implications using MICE models.

\item Model Application Guidelines: \cite{Essington_Plaganyi_2014} provided critical guidelines for adapting ecosystem models to new applications. \cite{Gamble_Link_2009} demonstrated multispecies production model applications for analyzing ecological and fishing effects.

\item Integrated Systems: \cite{Hadley_Wild-Allen_Johnson_Macleod_2015} and \cite{Oca_Cremades_Jimenez_Pintado_Masalo_2019} explored integrated multi-trophic aquaculture modeling, providing insights into coupled biological systems. \cite{Spillias_Cottrell_2024} analyzed trade-offs in seaweed farming between food production, livelihoods, marine biodiversity, and carbon sequestration benefits.
\end{itemize}

These papers were selected based on their direct relevance to COTS population dynamics, coral reef ecology, and ecosystem modeling approaches. The collection provided both specific parameter values and broader ecological context for model development.

\section{RAG Architecture Implementation}
\label{subsec:rag_architecture}

The Retrieval-Augmented Generation (RAG) system facilitates parameter search and extraction from scientific literature. The system employs two primary search strategies: a local search of user-curated documents and a comprehensive web search. For local search, the system uses ChromaDB as a persistent vector store to maintain an indexed collection of scientific papers and technical documents specifically curated by research teams for their ecological systems. These documents are processed into semantic chunks of approximately 512 tokens with small overlaps to preserve context while enabling precise retrieval of relevant information.

The parameter search process begins with the generation of enhanced semantic descriptions for each parameter. These descriptions are crafted to improve search relevance by capturing the ecological and mathematical context in which the parameters are used. The system first searches the user-curated local documents using embeddings generated through Azure OpenAI's embedding service. When necessary, it extends to web-based sources through two channels: querying the Semantic Scholar database for highly-cited papers in biology, mathematics, and environmental science, and conducting broader literature searches through the Serper API to capture additional relevant sources.

The search results from both local and web sources are processed through an LLM to extract numerical values. The system applies consistent validation across both search pathways, identifying minimum and maximum bounds, ensuring unit consistency, and validating source reliability. When direct parameter values are not found in either the local collection or web sources, the system defaults to the initial estimates from the coding LLM. All extracted information, including parameter values, valid ranges, and complete citation details, is stored in a structured JSON database for reproducibility and future reference.

The RAG system implements automatic retry mechanisms when initial searches fail to yield usable results. Each retry attempt follows a structured progression: first accessing the curated local collection through ChromaDB queries, then expanding to Semantic Scholar for peer-reviewed literature, and finally utilizing Serper API for broader scientific content. This progressive broadening of scope, while maintaining focus on ecologically relevant sources, ensures robust parameter estimation even in cases where direct measurements are sparse in the literature.

\section{AI Prompts Used in Model Development}
\label{sec:ai_prompts}

The development of the model relied on several carefully crafted prompts to guide the artificial intelligence system. These prompts were designed to ensure numerical stability, proper likelihood calculation, and clear model structure. The following sections detail the exact prompts used at each stage of model development.

\subsection{Initial Model Creation}
\label{subsec:initial_model_prompt}

The initial model creation utilized a comprehensive prompt that emphasized three key aspects of model development. The prompt used for model initialization was:

\begin{lstlisting}
Please create a Template Model Builder model for the following topic:[PROJECT_TOPIC]. Start by writing intention.txt, in which you provide a concise summary of the ecological functioning of the model. In model.cpp, write your TMB model with the following important considerations:

1. NUMERICAL STABILITY:
- Always use small constants (e.g., Type(1e-8)) to prevent division by zero
- Use smooth transitions instead of hard cutoffs in equations
- Bound parameters within biologically meaningful ranges using smooth penalties rather than hard constraints

2. LIKELIHOOD CALCULATION:
- Always include observations in the likelihood calculation, don't skip any based on conditions
- Use fixed minimum standard deviations to prevent numerical issues when data values are small
- Consider log-transforming data if it spans multiple orders of magnitude
- Use appropriate error distributions (e.g., lognormal for strictly positive data)

3. MODEL STRUCTURE:
- Include comments after each line explaining the parameters (including their units and how to determine their values)
- Provide a numbered list of descriptions for the equations
- Ensure all important variables are included in the reporting section
- Use `_pred' suffix for model predictions corresponding to `_dat' observations
\end{lstlisting}

\subsection{Parameter Enhancement}
\label{subsec:parameter_enhancement_prompt}

To enhance parameter descriptions for improved semantic search capabilities, the following prompt was employed:

\begin{lstlisting}
Given a mathematical model about [PROJECT_TOPIC], enhance the semantic descriptions of these parameters to be more detailed and searchable. The model code shows these parameters are used in the following way:

[MODEL_CONTENT]

For each parameter below, create an enhanced semantic search, no longer than 10 words, that can be used for RAG search or semantic scholar search.
\end{lstlisting}

\subsection{Model Improvement}
\label{subsec:model_improvement_prompt}

For iterative model improvements, the system utilized this prompt:

\begin{lstlisting}
Improve the fit of the following ecological model by modifying the equations in this TMB script. Only make ONE discrete change most likely to improve the fit. Do not add stochasticity, but you may add other ecological relevant factors that may not be present here already.

You may add additional parameters if necessary, and if so, add them to parameters.json. Please concisely describe your ecological improvement in intention.txt and then provide the improved model.cpp and parameters.json content.

\end{lstlisting}

\subsection{Error Handling Prompts}
\label{subsec:error_handling_prompt}

For compilation errors, the system used this prompt:

\begin{lstlisting}
model.cpp failed to compile. Here's the error information:

[ERROR_INFO]

Do not suggest how to compile the script
\end{lstlisting}

For data leakage issues, the system employed this detailed prompt:

\begin{lstlisting}
Data leakage detected in model equations. The following response variables cannot be used to predict themselves:

To fix this:
1. Response variables ([RESPONSE_VARS]) must be predicted using only:
   - External forcing variables ([FORCING_VARS])
   - Other response variables' predictions (_pred variables)
   - Parameters and constants
2. Each response variable must have a corresponding prediction equation
3. Use ecological relationships to determine how variables affect each other

For example, instead of:
  slow_pred(i) = slow * growth_rate;
Use:
  slow_pred(i) = slow_pred(i-1) * growth_rate * (1 - impact_rate * cots_pred(i-1));

Please revise the model equations to avoid using response variables to predict themselves.
\end{lstlisting}

For numerical instabilities, the system used an adaptive prompt that became progressively more focused on simplification after multiple attempts:

\begin{lstlisting}
The model compiled but numerical instabilities occurred. Here's the error information:

[ERROR_INFO]

[After 2+ attempts: Consider making a much simpler model that we can iteratively improve later.]
Do not suggest how to compile the script
\end{lstlisting}