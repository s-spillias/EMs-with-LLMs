\setcounter{section}{0}
\renewcommand{\thesection}{S\arabic{section}}

\input{supplement_blind/supp_methods}

\subsection{NPZ Case Study - Recovering Equations}
\label{subsec:npz_evaluation_prompt}

The model implementation can be compared to the original NPZ equations from \cite{edwards1999zooplankton}:

\begin{align*}
    \frac{dN}{dt} &= \underbrace{-\frac{V_m N P}{k_s + N}}_{\text{nutrient uptake}}
                   + \underbrace{\gamma(1-\alpha)\frac{g P^2 Z}{k_g + P^2} + \mu_P P + \mu_Z Z^2}_{\text{recycling}}
                   + \underbrace{S(N_0 - N)}_{\text{mixing}} \\[6pt]
    \frac{dP}{dt} &= \underbrace{\frac{V_m N P}{k_s + N}}_{\text{growth}}
                   - \underbrace{\frac{g P^2 Z}{k_g + P^2}}_{\text{grazing loss}}
                   - \underbrace{\mu_P P}_{\text{mortality}}
                   - \underbrace{S P}_{\text{mixing}} \\[6pt]
    \frac{dZ}{dt} &= \underbrace{\alpha\frac{g P^2 Z}{k_g + P^2}}_{\text{growth (assimilation)}}
                   - \underbrace{\mu_Z Z^2}_{\text{mortality}}
                   - \underbrace{S Z}_{\text{mixing}}
    \end{align*}

Our generated model captures several key ecological processes from the original system:
\begin{enumerate}
\item Nutrient uptake by phytoplankton following Michaelis-Menten kinetics
\item Quadratic zooplankton mortality
\item Nutrient recycling through zooplankton excretion
\item Environmental mixing effects
\end{enumerate}

For evaluating the ecological characteristics of generated models against the NPZ reference model, the system employed a 4-level ordinal scoring system that compares each model component to both the ground truth equations and recognized alternate formulations from the ecological literature. The evaluation system assessed nine ecological characteristics organized by equation: nutrient uptake, recycling, and mixing (dN/dt); phytoplankton growth, grazing loss, mortality, and mixing (dP/dt); and zooplankton growth and mortality (dZ/dt).

The scoring rubric used for all evaluations was:

\begin{lstlisting}
Scoring rubric per characteristic (choose exactly one category):
- 3 = TRUTH_MATCH
    The mathematical structure is equivalent to the TRUTH model (modulo variable names,
    syntax, factor grouping, and coefficient naming). Quote the exact snippet that matches.
- 2 = ALTERNATE
    The implementation matches one of the alternates enumerated in the literature catalog,
    even if not identical to TRUTH. Name the family (e.g., "Michaelis-Menten uptake",
    "Ivlev grazing with threshold", "linear mortality", "Droop quota").
- 1 = SIMILAR_NOT_LISTED
    The implementation plays the same ecological role and is mathematically similar
    (e.g., another saturating curve or plausible closure) but is not represented in TRUTH
    or alternates list.
- 0 = NOT_PRESENT_OR_INCORRECT
    The ecological component is missing or cannot be identified.
\end{lstlisting}

The alternate formulations catalog was based on \cite{franks2002npz} and included:

\begin{itemize}
    \item Phytoplankton light response: linear, saturating (Michaelis-Menten, exponential, tanh), and photo-inhibiting forms
    \item Nutrient uptake: Michaelis-Menten, Liebig minimum limitation, Droop quota models
    \item Zooplankton grazing: linear, saturating with threshold, Holling/Ivlev type, acclimating forms
    \item Mortality terms: linear and quadratic (density-dependent) for both phytoplankton and zooplankton
\end{itemize}

Each characteristic was assigned a weight based on its contribution to its parent equation: the three nutrient equation components each had weight 0.333, the four phytoplankton components each had weight 0.25, and the two zooplankton components each had weight 0.5. The aggregate ecological score was calculated as the weighted sum of individual scores, then normalized to a 0-1 scale by dividing by the maximum possible score.

\subsubsection{Validation of Scoring System}

To validate the ecological characteristics scoring system, we tested it on the ground truth NPZ model itself (evaluating the model against its own equations). This test confirmed that the scoring system could correctly identify and score all nine ecological characteristics when they were present in their canonical forms.

The validation results demonstrated perfect performance:

\begin{itemize}
    \item All nine characteristics received scores of 3 (TRUTH\_MATCH)
    \item Raw total score: 8.997 (out of maximum 9.0, with small rounding due to floating point arithmetic)
    \item Normalized total score: 1.0000 (perfect score on 0-1 scale)
    \item Zero extra components identified (correctly recognized model contained only canonical NPZ processes)
\end{itemize}

The LLM evaluator correctly identified each ecological mechanism in the ground truth model, providing detailed explanations such as ``algebraically identical to the TRUTH NPZ model'' and specifically noting the presence of ``Michaelis-Menten style nutrient limitation multiplied by a light/self-shading term for phytoplankton growth'' and ``a saturating P\textsuperscript{2}/(Âµ\textsuperscript{2}+P\textsuperscript{2}) (Hill/Type-III-like) grazing formulation.'' This validation confirmed that the scoring system could reliably distinguish between different levels of ecological fidelity, from exact matches to the ground truth through recognized alternates to novel formulations, providing a robust framework for assessing LEMMA-generated models.

\section{NPZ Validation}
\label{sec:npz_validation}

\input{supplement_blind/npz_analysis.tex}

\section{CoTS Model Convergence}
\label{sec:convergence}
    
\subsection{Model Evolution and Convergence}
The evolutionary process exhibited consistent refinement across generations, with measurable improvements in model performance. On average, populations reached their best-performing individual within 6.9 generations, and the mean improvement frequency across all populations was 38.0\%. Figure \ref{fig:status_distribution} shows the distribution of successful, culled, and broken models across generations. Notably, two populations achieved convergence below the target threshold, representing 9.5\% of all populations.
Performance varied significantly across populations. The fastest-converging population reached an optimal objective value of 0.0035 in just 3 generations, while others required up to 13 generations. This population also demonstrated a high improvement rate of -0.655 and a consistent improvement frequency of 50\%. In contrast, several populations showed minimal or no improvement, with some failing to converge within the allotted iterations.
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{../Figures/success_frequency}
\caption{Evolution of model performance during the genetic algorithm optimization process. Each generation represents an iteration of model development, where models are evaluated and classified into three categories: the best performers according to the NMSE objective value (kept, green), those that are numerically stable but outcompeted (culled, blue), and those that failed due to numerical instability, data leakage, or syntax errors (broken, orange). The vertical axis shows the count of new models in each category per generation, while rows represent independent replicates using different LLM configurations. Gemini-2.5-Pro was included in the analysis but did not produce successful runs for some populations.}
\label{fig:status_distribution}
\end{figure}

\subsection{Numerical Stability and Optimization}
Numerical stability varied across LLM configurations, with runtime and generation time metrics reflecting differences in optimization efficiency. The GPT-5 configuration showed moderate efficiency, with an average generation time of 12.0 minutes (SD = 13.0). The Claude Sonnet 4.5 configuration had longer generation times, averaging 71.2 minutes (SD = 155.2), though this includes variability from a small number of outlier populations. In contrast, the Gemini-2.5-Pro configuration demonstrated the fastest generation cycles, averaging 4.1 minutes per generation (SD = 0.54), though it exhibited lower convergence rates and higher instability in some cases.
Figure \ref{fig:iterations_by_llm} illustrates the distribution of iteration counts required for successful model convergence across LLMs. Most models converged within 4 to 7 iterations, with some outliers requiring up to 11 iterations.
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{../Figures/iterations_by_llm}
\caption{Distribution of iteration counts for successful model instances by LLM configuration. The boxplot excludes cases that reached maximum iterations or remained numerically unstable.}
\label{fig:iterations_by_llm}
\end{figure}

\input{supplement_blind/cots_analysis.tex}

% \input{best_models_read.tex}
\input{best_models/oos_best_read.tex}

